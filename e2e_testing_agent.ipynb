{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# E2E Testing Agent\n",
    "\n",
    "## Overview\n",
    "This notebook defines an intelligent agent designed to control a headless browser and perform end-to-end (E2E) testing on web pages. \n",
    "Users can specify the webpage URL and describe test cases in natural language. \n",
    "The agent will interpret these instructions, generate, and execute the tests.\n",
    "\n",
    "## Motivation\n",
    "In the era of AI-driven content creation, there's a growing demand for tools that can automate and simplify complex creative processes. This project aims to showcase how various AI technologies can be integrated to create a seamless workflow that transforms a simple text prompt into a dynamic visual story. By doing so, we're exploring the potential of AI in creative fields and providing a tool that could be valuable for content creators, educators, and enthusiasts alike.\n",
    "\n",
    "## Key Components\n",
    "1. [LangGraph](https://langchain-ai.github.io/langgraph/) - agent implementation\n",
    "2. [Playwright](https://github.com/microsoft/playwright-python) - a Python Playwright version that we can use to generate a script that can execute the test\n",
    "3. [Taipy](https://taipy.io/) - A library that we will use to spin up a simple website where we can demonstrate the capability of our agent\n",
    "4. [langchain_community.agent_toolkits.PlayWrightBrowserToolkit](https://python.langchain.com/v0.1/docs/integrations/toolkits/playwright/)\n",
    "\n",
    "## Method\n",
    "The E2E tests generation process goes through the following steps:\n",
    "\n",
    "1. **Instructions To Actions Conversion**: Convert user instruction for testing into well defined action steps that will be implemented.\n",
    "\n",
    "2. **Playwright Code Generation**: Generate Playwright code chunks that execute specified action steps.\n",
    "\n",
    "3. **Assertions Generation**: Creates assertions that specify whether the test have passed or not.\n",
    "\n",
    "4. **Test Execution**: Evaluates the generate Playwright test case.\n",
    "\n",
    "5. **Report Generation**: Creates the concise report of \n",
    "\n",
    "\n",
    "## Conclusion\n",
    "TODO: write concise conclusion."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup and Imports\n",
    "\n",
    "Import necessary libraries and set up the environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from typing import TypedDict, Annotated, Sequence, List\n",
    "from langgraph.graph import Graph, END\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.messages import HumanMessage, AIMessage\n",
    "from openai import OpenAI\n",
    "import io\n",
    "import os\n",
    "\n",
    "from langchain_core.runnables.graph import MermaidDrawMethod\n",
    "\n",
    "from IPython.display import display, Image\n",
    "import asyncio\n",
    "import aiohttp\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "os.environ[\"OPENAI_API_KEY\"] = os.getenv('OPENAI_API_KEY')\n",
    "\n",
    "client = OpenAI()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Data Structures\n",
    "\n",
    "Define the structure for the graph state using TypedDict."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GraphState(TypedDict):\n",
    "    messages: Annotated[Sequence[HumanMessage | AIMessage], \"The messages in the conversation\"]\n",
    "    instructions: Annotated[str, \"Instructions for the creation of the test case\"]\n",
    "\n",
    "llm = ChatOpenAI(model=\"gpt-4\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Graph Functions\n",
    "\n",
    "Define the functions that will be used in the LangGraph workflow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def convert_user_instruction_to_actions():\n",
    "    \"Parse user instructions into a list of actions to be executed\"\n",
    "    pass\n",
    "\n",
    "async def get_website_state(url: str):\n",
    "    \"\"\"Get the current DOM of the website\"\"\"\n",
    "    pass\n",
    "\n",
    "async def generate_code_for_action():\n",
    "    \"Generate code for a single action\"\n",
    "    pass\n",
    "\n",
    "async def get_action_generation_status():\n",
    "    \"Decides whether to stop the generation of the actions and move to the assertions\"\n",
    "    pass\n",
    "\n",
    "async def generate_assertions():\n",
    "    \"Generates test assertion that will be applied after action code\"\n",
    "    pass\n",
    "\n",
    "async def execute_test_case():\n",
    "    \"Execute the whole test case with its assertions\"\n",
    "    pass\n",
    "\n",
    "async def generate_test_report():\n",
    "    \"Generate the report from the test results\"\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set Up LangGraph Workflow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define graph with nodes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "workflow = Graph()\n",
    "\n",
    "workflow.add_node(\"convert_user_instruction_to_actions\", convert_user_instruction_to_actions)\n",
    "workflow.add_node(\"get_website_state\", get_website_state)\n",
    "workflow.add_node(\"generate_code_for_action\", generate_code_for_action)\n",
    "workflow.add_node(\"get_action_generation_status\", get_action_generation_status)\n",
    "workflow.add_node(\"generate_assertions\", generate_assertions)\n",
    "workflow.add_node(\"execute_test_case\", execute_test_case)\n",
    "workflow.add_node(\"generate_test_report\", generate_test_report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add edges to the graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "workflow.set_entry_point(\"convert_user_instruction_to_actions\")\n",
    "\n",
    "workflow.add_edge(\"convert_user_instruction_to_actions\", \"get_website_state\")\n",
    "workflow.add_edge(\"get_website_state\", \"generate_code_for_action\")\n",
    "workflow.add_edge(\"generate_code_for_action\", \"get_action_generation_status\")\n",
    "\n",
    "workflow.add_conditional_edges(\"get_action_generation_status\", lambda x: x, ['get_website_state', 'generate_assertions'])\n",
    "\n",
    "workflow.add_edge(\"generate_assertions\", \"execute_test_case\")\n",
    "workflow.add_edge(\"execute_test_case\", \"generate_test_report\")\n",
    "\n",
    "workflow.add_edge(\"generate_test_report\", END)\n",
    "\n",
    "\n",
    "\n",
    "app = workflow.compile()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Display Graph Structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(\n",
    "    Image(\n",
    "        app.get_graph().draw_mermaid_png(\n",
    "            draw_method=MermaidDrawMethod.API,\n",
    "        )\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Workflow Function\n",
    "\n",
    "Define a function to run the workflow and display results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Finish the workflow\n",
    "async def run_workflow(query: str):\n",
    "    \"\"\"Run the LangGraph workflow\"\"\"\n",
    "\n",
    "    try:\n",
    "        pass\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {str(e)}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Execute Workflow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Start up a Streamlit mockup page as a subprocess (does not block notebook execution) to evaluate the workflow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "\n",
    "process = subprocess.Popen(\n",
    "    [\"flask\", \"run\",],\n",
    "    env={\"FLASK_APP\": \"app.py\", \"FLASK_ENV\": \"development\", **os.environ}\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the workflow with a sample query."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Provide relevant query\n",
    "query = \"\"\n",
    "result = await run_workflow(query)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Terminate the Flask subprocess."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "process.kill() \n",
    "print(\"Flask app terminated.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Display Testing Report\n",
    "\n",
    "Display the report from the execution of the generated tests."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "e2e_agent",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
