{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# E2E Testing Agent\n",
    "\n",
    "## Overview\n",
    "This notebook defines an intelligent agent designed to control a headless browser and perform end-to-end (E2E) testing on web pages. \n",
    "Users can specify the webpage URL and describe test cases in natural language. \n",
    "The agent will interpret these instructions, generate, and execute the tests.\n",
    "\n",
    "## Motivation\n",
    "Programmatic browser control and E2E testing were traditionally done by writing scripts in frameworks such as Puppeteer or Playwright. We want to use the Agent system to allow the user to specify the E2E test cases in natural language. The agent will then create and execute these tests through Playwright.\n",
    "\n",
    "## Key Components\n",
    "1. [LangGraph](https://langchain-ai.github.io/langgraph/) - agent implementation\n",
    "2. [Playwright](https://github.com/microsoft/playwright-python) - a Python Playwright version that we can use to generate a script that can execute the test\n",
    "3. [Taipy](https://taipy.io/) - A library that we will use to spin up a simple website where we can demonstrate the capability of our agent\n",
    "4. [langchain_community.agent_toolkits.PlayWrightBrowserToolkit](https://python.langchain.com/v0.1/docs/integrations/toolkits/playwright/)\n",
    "\n",
    "## Method\n",
    "The E2E tests generation process goes through the following steps:\n",
    "\n",
    "1. **Instructions To Actions Conversion**: Convert user instruction for testing into well defined action steps that will be implemented.\n",
    "\n",
    "2. **Playwright Code Generation**: Generate Playwright code chunks that execute specified action steps.\n",
    "\n",
    "3. **Assertions Generation**: Creates assertions that specify whether the test have passed or not.\n",
    "\n",
    "4. **Test Execution**: Evaluates the generate Playwright test case.\n",
    "\n",
    "5. **Report Generation**: Creates the concise report of \n",
    "\n",
    "\n",
    "## Conclusion\n",
    "TODO: write concise conclusion."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup and Imports\n",
    "\n",
    "Import necessary libraries and set up the environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import ast\n",
    "\n",
    "from typing import TypedDict, Annotated, Sequence, List\n",
    "from langgraph.graph import Graph, END\n",
    "from langchain_openai import AzureChatOpenAI\n",
    "from langchain_core.messages import HumanMessage, AIMessage\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain.prompts.chat import SystemMessagePromptTemplate, HumanMessagePromptTemplate\n",
    "from langchain.output_parsers import PydanticOutputParser\n",
    "from langchain_core.runnables.graph import MermaidDrawMethod\n",
    "\n",
    "# These imports are unecessary for the playwrigt script execution\n",
    "from playwright.async_api import async_playwright\n",
    "import asyncio\n",
    "\n",
    "from pydantic import BaseModel, Field\n",
    "\n",
    "from IPython.display import display, Image\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initialize the LLM instance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = AzureChatOpenAI(\n",
    "    model_name=os.getenv(\"AZURE_OPENAI_LLM_MODEL\"),\n",
    "    deployment_name=os.getenv(\"AZURE_OPENAI_LLM_MODEL_DEPLOYMENT\"),\n",
    "    temperature=0.0,\n",
    "    streaming=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Data Structures\n",
    "\n",
    "Define the structure for the graph state using TypedDict."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GraphState(TypedDict):\n",
    "    messages: Annotated[Sequence[HumanMessage | AIMessage], \"The messages in the conversation\"]\n",
    "    query: Annotated[str, \"A user query containing instructions for the creation of the test case\"]\n",
    "    actions: Annotated[List[str], \"List of actions for which to generate the code.\"]\n",
    "    target_url: Annotated[str, \"Valid URL of the website to test.\"]\n",
    "    current_action: Annotated[int, \"The current action to generate the code for.\"]\n",
    "    current_action_code: Annotated[int, \"Code for the current action.\"]\n",
    "    script: Annotated[str, \"The generated Playwright script.\"]\n",
    "    website_state: Annotated[str, \"DOM state of the website.\"]\n",
    "\n",
    "class ActionList(BaseModel):\n",
    "    actions: List[str] = Field(..., description=\"List of atomic actions for end-to-end testing\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Graph Functions\n",
    "\n",
    "Define the functions that will be used in the LangGraph workflow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def convert_user_instruction_to_actions(state: GraphState) -> GraphState:\n",
    "    \"Parse user instructions into a list of actions to be executed.\"\n",
    "\n",
    "    output_parser = PydanticOutputParser(pydantic_object=ActionList)\n",
    "\n",
    "    chat_template = ChatPromptTemplate.from_messages(\n",
    "        [\n",
    "            SystemMessagePromptTemplate.from_template(\n",
    "                \"\"\"\n",
    "                You are an end-to-end testing specialist.\n",
    "                Your goal is to break down general business end-to-end testing tasks into smaller well-defined actions.\n",
    "                These actions will be later used to write the actual code that will execute the tests.\n",
    "                \"\"\"\n",
    "            ),\n",
    "            HumanMessagePromptTemplate.from_template(\n",
    "                \"\"\"\n",
    "                Convert the following <Input> into a JSON dictionary with the key \"actions\" and a list of atomic steps as its value.\n",
    "                These steps will later be used to generate end-to-end test scripts.\n",
    "                Each action should be a clear, atomic step that can be translated into code.\n",
    "                Aim to generate the minimum number of actions needed to accomplish what the user intends to test.\n",
    "                The first action must always be navigating to the target URL.\n",
    "                Do not add any extra characters, comments, or explanations outside of this JSON structure. Only output the JSON result.\n",
    "\n",
    "                Examples:\n",
    "                Input: \"Test the login flow of the website\"\n",
    "                Output: {{\n",
    "                    \"actions\": [\n",
    "                        \"Navigate to the login page via the URL.\",\n",
    "                        \"Locate and enter a valid email in the 'Email' input field\",\n",
    "                        \"Enter a valid password in the 'Password' input field\",\n",
    "                        \"Click the 'Login' button to submit credentials\",\n",
    "                        \"Verify that the user is logged in by validating that user name appears in the website header.\"\n",
    "                    ]\n",
    "                }}\n",
    "\n",
    "                Input: \"Test adding item to the shopping cart.\"\n",
    "                Output: {{\n",
    "                    \"actions\": [\n",
    "                        \"Navigate to the product listing page via the URL.\",\n",
    "                        \"Click on the first product in the listing to open product details\",\n",
    "                        \"Click the 'Add to Cart' button to add the selected item\",\n",
    "                        \"Verify the selected item appears in the shopping cart sidebar or page\"\n",
    "                    ]\n",
    "                }}\n",
    "\n",
    "                <Inptut>: {query}\n",
    "                <Output>:\n",
    "                \"\"\"\n",
    "            ),\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    chain = chat_template | llm | output_parser\n",
    "\n",
    "    actions_structure = chain.invoke({\"query\": state[\"query\"]})\n",
    "\n",
    "    return {**state, \"actions\": actions_structure.actions}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note: to run Playwright in Jupyter on windows you need to follow this issue https://github.com/microsoft/playwright-python/issues/178#issuecomment-1302869947\n",
    "async def get_initial_action(state: GraphState) -> GraphState:\n",
    "    \"\"\"Initialize a Playwright script with first action. This action is always navigation to the target URL and DOM state retrieval.\"\"\"\n",
    "    initial_script = f\"\"\"\n",
    "async def generated_script_run():\n",
    "    async with async_playwright() as p:\n",
    "        browser = await p.chromium.launch()\n",
    "        page = await browser.new_page()\n",
    "\n",
    "        # Action 0\n",
    "        await page.goto(\"{state['target_url']}\")\n",
    "        \n",
    "        # Next Action\n",
    "\n",
    "        dom_state = await page.content()\n",
    "        await browser.close()\n",
    "        return dom_state\n",
    "\n",
    "\"\"\"\n",
    "    \n",
    "    return {\n",
    "        **state,\n",
    "        \"script\": initial_script,\n",
    "        \"current_action\": state[\"current_action\"] + 1\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def get_website_state(state: GraphState) -> GraphState:\n",
    "    \"\"\"Get the current DOM of the website\"\"\"\n",
    "\n",
    "    exec(state[\"script\"])\n",
    "    dom_content = await generated_script_run()\n",
    "\n",
    "    return {\n",
    "        **state,\n",
    "        'website_state': dom_content\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def generate_code_for_action(state: GraphState) -> GraphState:\n",
    "    \"Generate code for the current action.\"\n",
    "    chat_template = ChatPromptTemplate.from_messages(\n",
    "        [\n",
    "            SystemMessagePromptTemplate.from_template(\n",
    "                \"\"\"\n",
    "                You are an end-to-end testing specialist. Your goal is to write a Python Playwright code for an action specified by the user.\n",
    "                \"\"\"\n",
    "            ),\n",
    "            HumanMessagePromptTemplate.from_template(\n",
    "                \"\"\"\n",
    "                You will be provided with a website <DOM> and the <Action> for which to write a Python Playwright code.\n",
    "                This code will be inserted into an existing Playwright code. Therefore the code should be atomic.\n",
    "                Also, assume that browser and page variables are defined and that you are operating on the page provided in the <DOM>.\n",
    "                When locating elements in the <DOM> try to use the data-testid attribute as a selector if it exists.\n",
    "                If the data-testid attribute is not present on the element of interest use a different selector.\n",
    "                Your output should be only an atomic Python Playwright code that fulfils the action.\n",
    "                Do not enclose the code in backticks or any Markdown formatting; output only the Python code itself!\n",
    "\n",
    "                <DOM>: {website_state}\n",
    "                ---\n",
    "                <Action>: {action}\n",
    "                ---\n",
    "                <Output>: \n",
    "                \"\"\"\n",
    "            ),\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    chain = chat_template | llm\n",
    "\n",
    "    current_action = state[\"actions\"][state[\"current_action\"]]\n",
    "\n",
    "    current_action_code = chain.invoke({\"action\": current_action, \"website_state\": state[\"website_state\"]}).content\n",
    "\n",
    "    return {\n",
    "        **state,\n",
    "        'current_action_code': current_action_code\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def validate_generated_action(state: GraphState) -> GraphState:\n",
    "    \"\"\"Validate the generated action code and insert it into the script if valid.\"\"\"\n",
    "    current_action_code = state['current_action_code']\n",
    "    current_action = state['current_action']\n",
    "    script = state['script']\n",
    "    \n",
    "    try:\n",
    "        ast.parse(current_action_code)\n",
    "    except SyntaxError as e:\n",
    "        error_message = f'Invalid Python code: {e}'\n",
    "        # TODO: this should instead lead to the end node in the graph and printing error\n",
    "        raise Exception(error_message)\n",
    "        \n",
    "    \n",
    "    # Check whether current_action_code contains at least one Playwright page command\n",
    "    if 'page.' not in current_action_code:\n",
    "        error_message = 'No Playwright page command found in current_action_code.'\n",
    "        # TODO: this should instead lead to the end node in the graph and printing error\n",
    "        raise Exception(error_message)\n",
    "        \n",
    "    # The indentation level (two levels for the nested functions)\n",
    "    indentation = '    ' * 2 \n",
    "    \n",
    "    code_lines = current_action_code.split('\\n')\n",
    "    indented_code_lines = [indentation + line for line in code_lines]\n",
    "    indented_current_action_code = '\\n'.join(indented_code_lines)\n",
    "    \n",
    "    code_to_insert = (\n",
    "        f'# Action {current_action}\\n'\n",
    "        f'{indented_current_action_code}\\n'\n",
    "        f'\\n{indentation}# Next Action'\n",
    "    )\n",
    "    script_updated = re.sub(r'# Next Action', code_to_insert, script, count=1)\n",
    "    \n",
    "    return {\n",
    "        **state,\n",
    "        'script': script_updated,\n",
    "        'current_action': current_action + 1,\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def generate_assertions(state: GraphState) -> GraphState:\n",
    "    \"Generates test assertion that will be applied after action code\"\n",
    "    pass\n",
    "\n",
    "async def execute_test_case(state: GraphState) -> GraphState:\n",
    "    \"Execute the whole test case with its assertions\"\n",
    "    pass\n",
    "\n",
    "async def generate_test_report(state: GraphState) -> GraphState:\n",
    "    \"Generate the report from the test results\"\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Existing Actions\n",
    "TODO: To be deleted when project is finished"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_initial_state = {\n",
    "    'messages': [],\n",
    "    'query':\"Test a registration form that contains username, password and password confirmation fields. After submitting it, verify that registration was successful.\",\n",
    "    'actions': [],\n",
    "    'target_url': \"http://localhost:5000\",\n",
    "    'current_action': 0,\n",
    "    'current_action_code': \"\",\n",
    "    'script': None,\n",
    "    'website_state': None\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_initial_state = await convert_user_instruction_to_actions(test_initial_state)\n",
    "print(\"State after convert_user_instruction_to_actions: \")\n",
    "test_initial_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_initial_state = await get_initial_action(test_initial_state)\n",
    "print(\"State after get_initial_action:\")\n",
    "test_initial_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_initial_state = await get_website_state(test_initial_state)\n",
    "print(\"State after get_website_state:\")\n",
    "test_initial_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_initial_state = await generate_code_for_action(test_initial_state)\n",
    "print(\"State after generate_code_for_action:\")\n",
    "test_initial_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_initial_state = await validate_generated_action(test_initial_state)\n",
    "print(\"State after generate_code_for_action:\")\n",
    "test_initial_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(test_initial_state['script'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set Up LangGraph Workflow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define graph with nodes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "workflow = Graph()\n",
    "\n",
    "workflow.add_node(\"convert_user_instruction_to_actions\", convert_user_instruction_to_actions)\n",
    "workflow.add_node(\"get_initial_action\", get_initial_action)\n",
    "workflow.add_node(\"get_website_state\", get_website_state)\n",
    "workflow.add_node(\"generate_code_for_action\", generate_code_for_action)\n",
    "workflow.add_node(\"get_action_generation_status\", validate_generated_action)\n",
    "workflow.add_node(\"generate_assertions\", generate_assertions)\n",
    "workflow.add_node(\"execute_test_case\", execute_test_case)\n",
    "workflow.add_node(\"generate_test_report\", generate_test_report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add edges to the graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "workflow.set_entry_point(\"convert_user_instruction_to_actions\")\n",
    "\n",
    "workflow.add_edge(\"convert_user_instruction_to_actions\", \"get_initial_action\")\n",
    "workflow.add_edge(\"get_initial_action\", \"get_website_state\")\n",
    "workflow.add_edge(\"get_website_state\", \"generate_code_for_action\")\n",
    "workflow.add_edge(\"generate_code_for_action\", \"validate_generated_action\")\n",
    "\n",
    "workflow.add_conditional_edges(\"validate_generated_action\", lambda x: x, ['get_website_state', 'generate_assertions'])\n",
    "\n",
    "workflow.add_edge(\"generate_assertions\", \"execute_test_case\")\n",
    "workflow.add_edge(\"execute_test_case\", \"generate_test_report\")\n",
    "\n",
    "workflow.add_edge(\"generate_test_report\", END)\n",
    "\n",
    "\n",
    "\n",
    "app = workflow.compile()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Display Graph Structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(\n",
    "    Image(\n",
    "        app.get_graph().draw_mermaid_png(\n",
    "            draw_method=MermaidDrawMethod.API,\n",
    "        )\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Workflow Function\n",
    "\n",
    "Define a function to run the workflow and display results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Finish the workflow\n",
    "async def run_workflow(query: str, target_url: str):\n",
    "    \"\"\"Run the LangGraph workflow\"\"\"\n",
    "    try:\n",
    "        initial_state = {\n",
    "            'messages': [],\n",
    "            'query': query,\n",
    "            'actions': [],\n",
    "            'target_url': target_url,\n",
    "            'current_action': 0,\n",
    "            'current_action_code': \"\",\n",
    "            'script': None,\n",
    "            'website_state': None\n",
    "        }\n",
    "\n",
    "        result = await app.ainvoke(initial_state)\n",
    "\n",
    "        return result\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {str(e)}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Execute Workflow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Start up a Streamlit mockup page as a subprocess (does not block notebook execution) to evaluate the workflow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "\n",
    "process = subprocess.Popen(\n",
    "    [\"flask\", \"run\",],\n",
    "    env={\"FLASK_APP\": \"app.py\", \"FLASK_ENV\": \"development\", **os.environ}\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the workflow with a sample query."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"Test a registration form that contains username, password and password confirmation fields. After submitting it, verify that registration was successful.\"\n",
    "target_url = \"http://localhost:5000\"\n",
    "result = await run_workflow(query, target_url)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Terminate the Flask subprocess."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "process.kill() \n",
    "print(\"Flask app terminated.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Display Testing Report\n",
    "\n",
    "Display the report from the execution of the generated tests."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "e2e_agent",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
